---
title: "Text Mining"
author: "Lucas"
date: "31/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Import Data
```{r cars}
library(tm)
library(dplyr)
library(tidytext)
library(ggplot2)
library(wordcloud2)
library(tidyverse)
library(topicmodels)
library(widyr)
library(igraph)
library(ggraph)

y1<-read.delim2("J:/Lucas/TextMining/theme1futureLandscapes.txt",header = FALSE, stringsAsFactors = FALSE)
y2<-read.delim2("J:/Lucas/TextMining/theme2incentivesForChange.txt",header = FALSE, stringsAsFactors = FALSE)
y3<-read.delim2("J:/Lucas/TextMining/theme3capacityForTransition.txt",header = FALSE, stringsAsFactors = FALSE)
Encoding(y1$V1) <- "UTF-8"
Encoding(y2$V1) <- "UTF-8"
Encoding(y3$V1) <- "UTF-8"


data<- bind_rows(y1%>%mutate(Topic = "Future_Landscapes"),
                 y2%>%mutate(Topic = "Incentives_For_Change"),
                 y3%>%mutate(Topic = "Capacity_For_Transition"))
```


stop_words - My Stop Words
```{r pressure, echo=FALSE}
stop_words
my_stopwords <- tibble(word = c(as.character(1:10),"e.g" ))
```



Words

Frequency
```{r pressure, echo=FALSE}
dataf1 <- data %>% 
  unnest_tokens(word,V1) %>%
  filter(!str_detect(word, "^[0-9]*$"))%>%
  anti_join(stop_words)%>%
  anti_join(my_stopwords)%>%
  count(word,sort = TRUE)

dataf1 %>%
  filter(n > 10) %>% #top_n(10)
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()

set.seed(222)
dataf1 %>%filter(n>2)%>%
  wordcloud2(word,size = .5,shape ="oval" , rotateRatio = 0.5,ellipticity = 0.9, color = "brown")


dataf2 <- data %>% 
  unnest_tokens(word,V1) %>%
  filter(!str_detect(word, "^[0-9]*$"))%>%
  anti_join(stop_words)%>%
  anti_join(my_stopwords)%>%
  count(Topic, word,sort = TRUE)%>%
  mutate(word= fct_reorder(word,n))%>%
  mutate(Topic = factor(Topic,levels = c("Future_Landscapes","Incentives_For_Change","Capacity_For_Transition")) )


dataf2 %>%
  group_by(Topic) %>%
  top_n(10,n) %>%
  ungroup() %>%
  ggplot(aes(reorder_within(word,n,Topic), n, fill = Topic)) +
  geom_col(show.legend = FALSE) +
  scale_x_reordered()+
  facet_wrap(~Topic, scales = "free") +
  labs(y = " ",
       x = NULL) +
  coord_flip()
```








statistic tf_idf(term frequency inverse document frequency): 
to measure how important a word is to a document in a collection of docunments  


```{r pressure, echo=FALSE}
data_tfidf<-dataf2%>%bind_tf_idf(word, Topic, n)


data_tfidf%>%
  arrange(desc(tf_idf))%>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(Topic) %>% 
  top_n(10) %>% 
  ungroup() %>%
  ggplot(aes(word, tf_idf, fill = Topic)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~Topic, scales = "free") +
  coord_flip()

```



Relationships between words:

Words Correlation - consecutive sequence of word

word Frequency

```{r pressure, echo=FALSE}
datac1<-data %>% 
  unnest_tokens(bigram,V1,token = "ngrams", n=2) %>%
  separate(bigram, c("word1", "word2"), sep = " ")%>%
  filter(!word1 %in% c(stop_words$word,my_stopwords) & !str_detect(word1, "^[0-9]*$") )%>%
  filter(!word2 %in% c(stop_words$word,my_stopwords)& !str_detect(word2, "^[0-9]*$"))%>%
  count(word1, word2, sort = TRUE)%>%
  unite(bigram,word1,word2,sep = " ")


datac1 %>%
  filter(n > 2) %>% #top_n(10)
  mutate(bigram = reorder(bigram, n)) %>%
  ggplot(aes(bigram, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()


datac2<-data %>% 
  unnest_tokens(bigram,V1,token = "ngrams", n=2) %>%
  separate(bigram, c("word1", "word2"), sep = " ")%>%
  filter(!word1 %in% c(stop_words$word,my_stopwords) & !str_detect(word1, "^[0-9]*$") )%>%
  filter(!word2 %in% c(stop_words$word,my_stopwords)& !str_detect(word2, "^[0-9]*$"))%>%
  count(Topic, word1, word2, sort = TRUE)%>%
  unite(bigram,word1,word2,sep = " ")




datac2 %>%
  group_by(Topic) %>%
  top_n(9,n) %>%
  ungroup() %>%
  ggplot(aes(reorder_within(bigram,n,Topic), n, fill = Topic)) +
  geom_col(show.legend = FALSE) +
  scale_x_reordered()+
  facet_wrap(~Topic, scales = "free") +
  labs(y = " ",
       x = NULL) +
  coord_flip()

```

tf-idf-
```{r pressure, echo=FALSE}
datac2 %>%
  bind_tf_idf(bigram, Topic, n) %>%
  arrange(desc(tf_idf))%>%
mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>% 
  group_by(Topic) %>% 
  top_n(6) %>% 
  ungroup() %>%
  ggplot(aes(bigram, tf_idf, fill = Topic)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~Topic, scales = "free") +
  coord_flip()
```


ggraph by frequency - consecutive sequence of word
```{r pressure, echo=FALSE}
set.seed(2016)
a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

data %>% 
  unnest_tokens(bigram,V1,token = "ngrams", n=2) %>%
  separate(bigram, c("word1", "word2"), sep = " ")%>%
  filter(!word1 %in% c(stop_words$word,my_stopwords) & !str_detect(word1, "^[0-9]*$") )%>%
  filter(!word2 %in% c(stop_words$word,my_stopwords)& !str_detect(word2, "^[0-9]*$"))%>%
  count(word1, word2, sort = TRUE)%>%
  filter(n>1)%>%
  ggraph( layout = "fr") +
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +
  theme_void()
```


Correlating pairs:
words tend to co-occur even if they dont occur next to each other

(change n<2, correlation would be crucial of the performance )
```{r pressure, echo=FALSE}
wordcor<-data %>% 
  mutate(section = row_number() %/% 10) %>%
  unnest_tokens(word, V1) %>%
  filter(!word %in% c(stop_words$word,my_stopwords) & !str_detect(word, "^[0-9]*$") )%>%
  group_by(word)%>%
  filter(n() >2) %>% # 1
  pairwise_cor(word, section, sort = TRUE)


wordcor%>%
  filter(item1 %in% c("environmental", "water", "land")) %>%
  group_by(item1) %>%
  top_n(7) %>%
  ungroup() %>%
  ggplot(aes(reorder_within(item2,correlation,item1), correlation)) +
  geom_bar(stat = "identity") +
  scale_x_reordered()+
  facet_wrap(~ item1, scales = "free") +
  coord_flip()

set.seed(2019)
wordcor%>%  filter(correlation > .6) %>% # .9
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = FALSE) +
  geom_node_point(color = "lightblue", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()
```


Topic Modeling: a method for unsupervised classification, silimar to clustering on numeric data

Latent Dirichlet allocation(LDA) algorithm for fitting a topic model
1.finding the mixture of words associated with each topic
2.determine the mixture of topics that describes each document

data
```{r pressure, echo=FALSE}
datatm <- dataf2 %>%cast_dtm(Topic,word, n)
datatm <- LDA(datatm, k = 3, control = list(seed = 1234))
datatm1 <- tidy(datatm, matrix = "beta")
datatm2 <- tidy(datatm, matrix = "gamma")
```

```{r pressure, echo=FALSE}

datatm1 %>%
  group_by(topic) %>%
  top_n(20, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)%>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(term, beta, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  coord_flip() +
  scale_x_reordered()


datatm1 %>%
  mutate(topic = paste0("topic", topic)) %>%
  spread(topic, beta) %>%
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic2 / topic1)) %>%
  top_n(20,abs(log_ratio))%>%
  mutate(term = reorder(term,log_ratio))%>%
  ggplot(aes(term, log_ratio)) +
  geom_col(show.legend = FALSE) +
  ylab("Log2 ratio of beta in topic2 / topic1") +
  xlab("term") +
  coord_flip()

```


```{r pressure, echo=FALSE}
datatm2   %>%
  mutate(title = reorder(document, gamma)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ document)
datatm2%>%arrange(document,gamma)
```